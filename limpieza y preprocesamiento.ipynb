{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6bfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos cargados exitosamente.\n",
      "Dimensiones - articles: (105542, 25)\n",
      "Dimensiones - customers: (1371980, 7)\n",
      "Dimensiones - transacciones: (1337996, 5)\n",
      "\n",
      "Uniendo transacciones con clientes...\n",
      "Uniendo el resultado con los artículos...\n",
      "\n",
      "¡Unión completada!\n",
      "Dimensiones del DataFrame final 'full_df': (1337996, 35)\n",
      "\n",
      "Primeras 5 filas del DataFrame combinado 'full_df':\n",
      "        t_dat                                        customer_id  article_id  \\\n",
      "0  2018-09-20  00be0a263381af38132d31225e8fb12fbc527c654b4464...   644522001   \n",
      "1  2018-09-20  012bbedf2efe728a7407a5dc842a852f8e09e9ae972711...   651456003   \n",
      "2  2018-09-20  012bbedf2efe728a7407a5dc842a852f8e09e9ae972711...   651456003   \n",
      "3  2018-09-20  012bbedf2efe728a7407a5dc842a852f8e09e9ae972711...   651456003   \n",
      "4  2018-09-20  0137b87739a796f65396d8483173f66318039d19a2583f...   577992001   \n",
      "\n",
      "      price  sales_channel_id   FN  Active club_member_status  \\\n",
      "0  0.059305                 2  1.0     1.0             ACTIVE   \n",
      "1  0.016932                 1  1.0     1.0             ACTIVE   \n",
      "2  0.016932                 1  1.0     1.0             ACTIVE   \n",
      "3  0.016932                 1  1.0     1.0             ACTIVE   \n",
      "4  0.011254                 2  1.0     1.0             ACTIVE   \n",
      "\n",
      "  fashion_news_frequency   age  ...  department_name  index_code  \\\n",
      "0              Regularly  22.0  ...            Heels           C   \n",
      "1              Regularly  24.0  ...     Jersey Basic           A   \n",
      "2              Regularly  24.0  ...     Jersey Basic           A   \n",
      "3              Regularly  24.0  ...     Jersey Basic           A   \n",
      "4              Regularly  25.0  ...  Casual Lingerie           B   \n",
      "\n",
      "           index_name  index_group_no index_group_name section_no  \\\n",
      "0  Ladies Accessories               1       Ladieswear         64   \n",
      "1          Ladieswear               1       Ladieswear         16   \n",
      "2          Ladieswear               1       Ladieswear         16   \n",
      "3          Ladieswear               1       Ladieswear         16   \n",
      "4    Lingeries/Tights               1       Ladieswear         61   \n",
      "\n",
      "             section_name garment_group_no  garment_group_name  \\\n",
      "0            Womens Shoes             1020               Shoes   \n",
      "1  Womens Everyday Basics             1002        Jersey Basic   \n",
      "2  Womens Everyday Basics             1002        Jersey Basic   \n",
      "3  Womens Everyday Basics             1002        Jersey Basic   \n",
      "4         Womens Lingerie             1017   Under-, Nightwear   \n",
      "\n",
      "                                         detail_desc  \n",
      "0  Ankle boots with peep toes and visible seams. ...  \n",
      "1  Short-sleeved tops in organic cotton jersey wi...  \n",
      "2  Short-sleeved tops in organic cotton jersey wi...  \n",
      "3  Short-sleeved tops in organic cotton jersey wi...  \n",
      "4  Brazilian briefs in cotton jersey and lace wit...  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Carga de los tres archivos CSV ---\n",
    "try:\n",
    "    df_articles = pd.read_csv('Datos/articles.csv')\n",
    "    df_customers = pd.read_csv('Datos/customers.csv')\n",
    "    df_trans = pd.read_csv('Datos/young_female_trans.csv') # Asegúrate que el nombre del archivo es correcto\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo {e.filename}. Asegúrate de que los archivos CSV están en el mismo directorio que tu script o notebook.\")\n",
    "    # Detenemos la ejecución si los archivos no se encuentran\n",
    "    exit()\n",
    "\n",
    "print(\"Archivos cargados exitosamente.\")\n",
    "print(f\"Dimensiones - articles: {df_articles.shape}\")\n",
    "print(f\"Dimensiones - customers: {df_customers.shape}\")\n",
    "print(f\"Dimensiones - transacciones: {df_trans.shape}\")\n",
    "\n",
    "# --- Unión Estratégica de los DataFrames ---\n",
    "# 1. Unir transacciones con la información de los clientes\n",
    "print(\"\\nUniendo transacciones con clientes...\")\n",
    "merged_df = pd.merge(df_trans, df_customers, on='customer_id', how='left')\n",
    "\n",
    "# 2. Unir el resultado con la información de los artículos\n",
    "print(\"Uniendo el resultado con los artículos...\")\n",
    "full_df = pd.merge(merged_df, df_articles, on='article_id', how='left')\n",
    "\n",
    "print(\"\\n¡Unión completada!\")\n",
    "print(f\"Dimensiones del DataFrame final 'full_df': {full_df.shape}\")\n",
    "print(\"\\nPrimeras 5 filas del DataFrame combinado 'full_df':\")\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3eee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas detectadas automáticamente: ['t_dat', 'customer_id', 'club_member_status', 'fashion_news_frequency', 'postal_code', 'prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_code', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'detail_desc']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = full_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(\"Columnas categóricas detectadas automáticamente:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53c0c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Paso 2: Limpieza y Preprocesamiento ---\n",
      "Valores nulos en 'age' rellenados con la mediana: 25.0\n",
      "Valores nulos en 'club_member_status' rellenados con 'Unknown'.\n",
      "Valores nulos en 'fashion_news_frequency' rellenados con 'Unknown'.\n",
      "Columna 't_dat' convertida a formato datetime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_25016\\3919899993.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  full_df['age'].fillna(median_age, inplace=True)\n",
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_25016\\3919899993.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  full_df[col].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de ID convertidas a tipo string.\n",
      "\n",
      "¡Limpieza y Preprocesamiento completados!\n",
      "\n",
      "Información del DataFrame 'full_df' después de la limpieza:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1337996 entries, 0 to 1337995\n",
      "Data columns (total 35 columns):\n",
      " #   Column                        Non-Null Count    Dtype         \n",
      "---  ------                        --------------    -----         \n",
      " 0   t_dat                         1337996 non-null  datetime64[ns]\n",
      " 1   customer_id                   1337996 non-null  object        \n",
      " 2   article_id                    1337996 non-null  object        \n",
      " 3   price                         1337996 non-null  float64       \n",
      " 4   sales_channel_id              1337996 non-null  int64         \n",
      " 5   FN                            1337996 non-null  float64       \n",
      " 6   Active                        1337996 non-null  float64       \n",
      " 7   club_member_status            1337996 non-null  object        \n",
      " 8   fashion_news_frequency        1337996 non-null  object        \n",
      " 9   age                           1337996 non-null  float64       \n",
      " 10  postal_code                   1337996 non-null  object        \n",
      " 11  product_code                  1337996 non-null  int64         \n",
      " 12  prod_name                     1337996 non-null  object        \n",
      " 13  product_type_no               1337996 non-null  int64         \n",
      " 14  product_type_name             1337996 non-null  object        \n",
      " 15  product_group_name            1337996 non-null  object        \n",
      " 16  graphical_appearance_no       1337996 non-null  int64         \n",
      " 17  graphical_appearance_name     1337996 non-null  object        \n",
      " 18  colour_group_code             1337996 non-null  int64         \n",
      " 19  colour_group_name             1337996 non-null  object        \n",
      " 20  perceived_colour_value_id     1337996 non-null  int64         \n",
      " 21  perceived_colour_value_name   1337996 non-null  object        \n",
      " 22  perceived_colour_master_id    1337996 non-null  int64         \n",
      " 23  perceived_colour_master_name  1337996 non-null  object        \n",
      " 24  department_no                 1337996 non-null  int64         \n",
      " 25  department_name               1337996 non-null  object        \n",
      " 26  index_code                    1337996 non-null  object        \n",
      " 27  index_name                    1337996 non-null  object        \n",
      " 28  index_group_no                1337996 non-null  int64         \n",
      " 29  index_group_name              1337996 non-null  object        \n",
      " 30  section_no                    1337996 non-null  int64         \n",
      " 31  section_name                  1337996 non-null  object        \n",
      " 32  garment_group_no              1337996 non-null  int64         \n",
      " 33  garment_group_name            1337996 non-null  object        \n",
      " 34  detail_desc                   1333401 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(11), object(19)\n",
      "memory usage: 357.3+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Iniciando Paso 2: Limpieza y Preprocesamiento ---\")\n",
    "\n",
    "# --- Manejo de Valores Nulos ---\n",
    "# Rellenar la edad faltante con la mediana\n",
    "if 'age' in full_df.columns:\n",
    "    median_age = full_df['age'].median()\n",
    "    full_df['age'].fillna(median_age, inplace=True)\n",
    "    print(f\"Valores nulos en 'age' rellenados con la mediana: {median_age}\")\n",
    "else:\n",
    "    print(\"Advertencia: La columna 'age' no se encontró en 'customers.csv'.\")\n",
    "\n",
    "\n",
    "# Rellenar nulos en columnas categóricas importantes\n",
    "# Iteramos sobre una lista de columnas para mantener el código limpio\n",
    "categorical_cols_to_fill = ['club_member_status', 'fashion_news_frequency']\n",
    "for col in categorical_cols_to_fill:\n",
    "    if col in full_df.columns:\n",
    "        full_df[col].fillna('Unknown', inplace=True)\n",
    "        print(f\"Valores nulos en '{col}' rellenados con 'Unknown'.\")\n",
    "\n",
    "# --- Conversión de Tipos de Datos ---\n",
    "# Convertir la columna de fecha a formato datetime\n",
    "full_df['t_dat'] = pd.to_datetime(full_df['t_dat'])\n",
    "print(\"Columna 't_dat' convertida a formato datetime.\")\n",
    "\n",
    "# Asegurarse de que los IDs son tratados como strings (categóricos)\n",
    "full_df['customer_id'] = full_df['customer_id'].astype(str)\n",
    "full_df['article_id'] = full_df['article_id'].astype(str)\n",
    "print(\"Columnas de ID convertidas a tipo string.\")\n",
    "\n",
    "print(\"\\n¡Limpieza y Preprocesamiento completados!\")\n",
    "print(\"\\nInformación del DataFrame 'full_df' después de la limpieza:\")\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca110385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Paso 3: Ingeniería de Características ---\n",
      "Creando perfiles de usuario...\n",
      "Perfiles de usuario creados exitosamente.\n",
      "                                         customer_id   age  avg_price_paid  \\\n",
      "0  00066fdcf5f0da690b898b287d05ce477bd2764ce975d1...  28.0        0.026779   \n",
      "1  0010e8eb18f131e724d6997909af0808adbba057529edb...  25.0        0.026849   \n",
      "2  0013bde09d10db6b0a6a3b0987ac60b643013dfc6f924b...  27.0        0.024092   \n",
      "3  00155b2ef48cfb5d2fce4642f670f151efe0747542a5b9...  21.0        0.026822   \n",
      "4  001a7fb6def4cc4de27cb02f0025ea28c8ee74efdd3c73...  24.0        0.017949   \n",
      "\n",
      "   total_articles_bought fav_product_type fav_color        fav_department  \n",
      "0                     21           Shorts      Blue  Denim Other Garments  \n",
      "1                     90         Trousers     Black          Jersey Basic  \n",
      "2                     19         Trousers     Black              Swimwear  \n",
      "3                     67          Sweater     Black       Casual Lingerie  \n",
      "4                     10       Bikini top     Black              Swimwear  \n",
      "\n",
      "Creando características de producto (versión refinada)...\n",
      "Características de producto refinadas y creadas exitosamente.\n",
      "  article_id product_type_name  product_group_name graphical_appearance_name  \\\n",
      "0  108775015          Vest top  Garment Upper body                     Solid   \n",
      "1  108775044          Vest top  Garment Upper body                     Solid   \n",
      "2  108775051          Vest top  Garment Upper body                    Stripe   \n",
      "3  110065001               Bra           Underwear                     Solid   \n",
      "4  110065002               Bra           Underwear                     Solid   \n",
      "\n",
      "  colour_group_name department_name        index_name            section_name  \\\n",
      "0             Black    Jersey Basic        Ladieswear  Womens Everyday Basics   \n",
      "1             White    Jersey Basic        Ladieswear  Womens Everyday Basics   \n",
      "2         Off White    Jersey Basic        Ladieswear  Womens Everyday Basics   \n",
      "3             Black  Clean Lingerie  Lingeries/Tights         Womens Lingerie   \n",
      "4             White  Clean Lingerie  Lingeries/Tights         Womens Lingerie   \n",
      "\n",
      "  garment_group_name  times_purchased  \n",
      "0       Jersey Basic            398.0  \n",
      "1       Jersey Basic            289.0  \n",
      "2       Jersey Basic              7.0  \n",
      "3  Under-, Nightwear             27.0  \n",
      "4  Under-, Nightwear             17.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_25016\\678449916.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_item_features['times_purchased'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Iniciando Paso 3: Ingeniería de Características ---\")\n",
    "\n",
    "# --- 3.1. Creación de Perfiles de Usuario ---\n",
    "print(\"Creando perfiles de usuario...\")\n",
    "user_profiles = full_df.groupby('customer_id').agg(\n",
    "    # Característica demográfica\n",
    "    age=('age', 'first'),  # 'first' toma el primer valor, ya que es constante por usuario\n",
    "    \n",
    "    # Características de comportamiento\n",
    "    avg_price_paid=('price', 'mean'),\n",
    "    total_articles_bought=('article_id', 'count'),\n",
    "    \n",
    "    # Características de \"Gusto\" (usando la moda)\n",
    "    # Usamos una función lambda para manejar casos donde un usuario no tiene datos para una categoría\n",
    "    fav_product_type=('product_type_name', lambda x: x.mode()[0] if not x.empty else 'Unknown'),\n",
    "    fav_color=('colour_group_name', lambda x: x.mode()[0] if not x.empty else 'Unknown'),\n",
    "    fav_department=('department_name', lambda x: x.mode()[0] if not x.empty else 'Unknown')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Perfiles de usuario creados exitosamente.\")\n",
    "print(user_profiles.head())\n",
    "\n",
    "# --- 3.2. Creación de Características de Producto (Refinado) ---\n",
    "print(\"\\nCreando características de producto (versión refinada)...\")\n",
    "\n",
    "# Calcular popularidad del artículo\n",
    "item_popularity = full_df.groupby('article_id').agg(\n",
    "    times_purchased=('customer_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# --- SELECCIÓN EXPLÍCITA DE FEATURES ---\n",
    "# Seleccionamos las características categóricas que son útiles y tienen una cardinalidad manejable.\n",
    "# EXCLUIMOS: prod_name, detail_desc, y columnas de código/ID que no usaremos.\n",
    "good_static_item_features = [\n",
    "    'article_id', 'product_type_name', 'product_group_name', 'graphical_appearance_name', \n",
    "    'colour_group_name', 'department_name', 'index_name', 'section_name', 'garment_group_name'\n",
    "]\n",
    "# Asegurarnos de que todas las columnas seleccionadas existen en el DataFrame\n",
    "existing_good_features = [col for col in good_static_item_features if col in df_articles.columns]\n",
    "\n",
    "static_item_features = df_articles[existing_good_features].copy()\n",
    "static_item_features['article_id'] = static_item_features['article_id'].astype(str)\n",
    "\n",
    "# Unir características estáticas con las dinámicas (popularidad)\n",
    "final_item_features = pd.merge(static_item_features, item_popularity, on='article_id', how='left')\n",
    "final_item_features['times_purchased'].fillna(0, inplace=True)\n",
    "\n",
    "print(\"Características de producto refinadas y creadas exitosamente.\")\n",
    "print(final_item_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9f0c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Paso 4: Creación del Dataset de Entrenamiento ---\n",
      "Número de ejemplos positivos (interacciones únicas): 1120412\n",
      "Generando ejemplos negativos... (Esto puede tardar un poco)\n",
      "Número de ejemplos negativos generados: 2240824\n",
      "\n",
      "Combinando positivos, negativos y features...\n",
      "\n",
      "¡Dataset de Entrenamiento 'training_data' creado y listo!\n",
      "Dimensiones finales: (3361236, 18)\n",
      "Distribución del target:\n",
      "target\n",
      "0    2240824\n",
      "1    1120412\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Primeras filas del dataset de entrenamiento final:\n",
      "                                         customer_id article_id  target   age  \\\n",
      "0  bf97c1a3e662bdc94bc917fcd81fc0923dd16bce6c2ec7...  691110001       0  29.0   \n",
      "1  78425dc9f364ee0fc7734f3204595f9ead322622bba183...  793111001       0  23.0   \n",
      "2  6cd6688b2571bd55f6b5d074aa6129ad7e6751f027153c...  672383004       0  24.0   \n",
      "3  39762eb23aa18643a655d99bc22b968cf3c4a4551bff1e...  748440001       0  22.0   \n",
      "4  b8f3c05e5318b7c9b0983dc15d1a9cfddfce12ac674fe3...  762585001       1  28.0   \n",
      "\n",
      "   avg_price_paid  total_articles_bought fav_product_type fav_color  \\\n",
      "0        0.033205                    295         Trousers     Black   \n",
      "1        0.028093                     83            Dress     Black   \n",
      "2        0.026746                     88         Trousers     Black   \n",
      "3        0.019545                    128            Dress     Black   \n",
      "4        0.016916                    166           Blouse     Black   \n",
      "\n",
      "  fav_department product_type_name  product_group_name  \\\n",
      "0       Swimwear           Sweater  Garment Upper body   \n",
      "1          Dress             Shirt  Garment Upper body   \n",
      "2         Blouse  Underwear bottom           Underwear   \n",
      "3          Flats            Blouse  Garment Upper body   \n",
      "4         Blouse          Trousers  Garment Lower body   \n",
      "\n",
      "  graphical_appearance_name colour_group_name      department_name  \\\n",
      "0                   Melange   Yellowish Brown    Studio Collection   \n",
      "1                     Solid             White       Blouse & Dress   \n",
      "2           Other structure             Black  Expressive Lingerie   \n",
      "3                     Solid             White               Blouse   \n",
      "4                     Solid             Black              Trouser   \n",
      "\n",
      "         index_name                section_name garment_group_name  \\\n",
      "0        Ladieswear         Special Collections            Unknown   \n",
      "1        Ladieswear                Womens Trend            Blouses   \n",
      "2  Lingeries/Tights             Womens Lingerie  Under-, Nightwear   \n",
      "3        Ladieswear               Womens Casual            Blouses   \n",
      "4        Ladieswear  Womens Everyday Collection           Trousers   \n",
      "\n",
      "   times_purchased  \n",
      "0              5.0  \n",
      "1             10.0  \n",
      "2              1.0  \n",
      "3             44.0  \n",
      "4             18.0  \n",
      "¡Dataset de entrenamiento final guardado exitosamente en 'training_data.parquet'!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Iniciando Paso 4: Creación del Dataset de Entrenamiento ---\")\n",
    "\n",
    "# --- 4.1. Crear Ejemplos Positivos ---\n",
    "positive_samples = full_df[['customer_id', 'article_id']].drop_duplicates().copy()\n",
    "positive_samples['target'] = 1\n",
    "print(f\"Número de ejemplos positivos (interacciones únicas): {len(positive_samples)}\")\n",
    "\n",
    "# --- 4.2. Crear Ejemplos Negativos (Negative Sampling) ---\n",
    "print(\"Generando ejemplos negativos... (Esto puede tardar un poco)\")\n",
    "\n",
    "# Crear un set de todos los IDs de artículos para una búsqueda eficiente\n",
    "all_article_ids = set(df_articles['article_id'].astype(str))\n",
    "\n",
    "# Diccionario para guardar los artículos comprados por cada usuario\n",
    "user_purchased_items = positive_samples.groupby('customer_id')['article_id'].apply(set)\n",
    "\n",
    "negative_samples_list = []\n",
    "negative_sample_ratio = 2 # Generar 2 negativos por cada positivo\n",
    "\n",
    "for customer_id, purchased_set in user_purchased_items.items():\n",
    "    # Artículos que el usuario no ha comprado\n",
    "    non_purchased_items = all_article_ids - purchased_set\n",
    "    \n",
    "    # Determinar cuántos negativos muestrear\n",
    "    num_neg_samples = len(purchased_set) * negative_sample_ratio\n",
    "    \n",
    "    # Tomar una muestra aleatoria de los no comprados\n",
    "    # Usamos min() para evitar errores si un usuario ha comprado casi todo\n",
    "    samples_to_take = min(num_neg_samples, len(non_purchased_items))\n",
    "    if samples_to_take > 0:\n",
    "        negative_choices = np.random.choice(list(non_purchased_items), size=samples_to_take, replace=False)\n",
    "        \n",
    "        for article_id in negative_choices:\n",
    "            negative_samples_list.append({'customer_id': customer_id, 'article_id': article_id, 'target': 0})\n",
    "\n",
    "negative_samples = pd.DataFrame(negative_samples_list)\n",
    "print(f\"Número de ejemplos negativos generados: {len(negative_samples)}\")\n",
    "\n",
    "# --- 4.3. Unir todo para el Dataset Final ---\n",
    "print(\"\\nCombinando positivos, negativos y features...\")\n",
    "\n",
    "# 1. Concatenar positivos y negativos\n",
    "training_data = pd.concat([positive_samples, negative_samples], ignore_index=True)\n",
    "\n",
    "# 2. Añadir las características del usuario\n",
    "training_data = pd.merge(training_data, user_profiles, on='customer_id', how='left')\n",
    "\n",
    "# 3. Añadir las características del producto\n",
    "training_data = pd.merge(training_data, final_item_features, on='article_id', how='left')\n",
    "\n",
    "# 4. Limpieza final: Rellenar posibles nulos que hayan surgido del merge\n",
    "training_data.fillna(0, inplace=True) # Una estrategia simple es rellenar con 0\n",
    "\n",
    "# 5. Mezclar el dataset para eliminar cualquier orden\n",
    "training_data = training_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n¡Dataset de Entrenamiento 'training_data' creado y listo!\")\n",
    "print(f\"Dimensiones finales: {training_data.shape}\")\n",
    "print(\"Distribución del target:\")\n",
    "print(training_data['target'].value_counts())\n",
    "print(\"\\nPrimeras filas del dataset de entrenamiento final:\")\n",
    "print(training_data.head())\n",
    "\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet\n",
    "output_path = 'training_data.parquet'\n",
    "training_data.to_parquet(output_path, engine='pyarrow')\n",
    "\n",
    "print(f\"¡Dataset de entrenamiento final guardado exitosamente en '{output_path}'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
